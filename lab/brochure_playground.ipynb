{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc21c74",
   "metadata": {},
   "source": [
    "# Lab: Brochure Generator Playground\n",
    "\n",
    "A sandbox to try the brochure pipeline (scraper → cleaner → optional Gemini) without touching the main app. Follow the sections below to set up, scrape, clean, and optionally generate a brochure.\n",
    "\n",
    "Outline covered here:\n",
    "- Setup project and kernel\n",
    "- Load and inspect sample data\n",
    "- Define helper functions (using existing services)\n",
    "- Run the main flow with toggles\n",
    "- Add quick tests\n",
    "- Validate outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d95161",
   "metadata": {},
   "source": [
    "## 1. Setup Project and Install Dependencies\n",
    "\n",
    "Use the project venv, install `requirements.txt`, then select that kernel. This cell wires sys.path to the repo root and loads `.env` so the notebook sees the same settings as the app.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9380f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel & env setup\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Point PYTHONPATH at repo root for imports\n",
    "PROJECT_ROOT = Path(__file__).resolve().parents[1]\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "load_dotenv(PROJECT_ROOT / \".env\")\n",
    "\n",
    "from config.settings import settings  # type: ignore\n",
    "\n",
    "# Toggle the target and whether to hit the LLM step\n",
    "target_url = \"https://example.com\"\n",
    "RUN_LLM = False  # set True only if APP_GOOGLE_API_KEY is configured\n",
    "\n",
    "print(f\"PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "print(f\"App: {settings.app_name} | Env: {settings.app_env}\")\n",
    "print(f\"Google API key set: {bool(settings.google_api_key)}\")\n",
    "print(f\"LLM enabled in this run: {RUN_LLM}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ed0687",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect Dataset\n",
    "\n",
    "We will use a tiny in-memory HTML sample as a fallback dataset for offline runs, while the live pipeline will pull from `target_url` when reachable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc050ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-memory fallback HTML (used if live scraping fails)\n",
    "fallback_main_html = \"\"\"\n",
    "<html>\n",
    "  <head><title>Example Co</title></head>\n",
    "  <body>\n",
    "    <header><h1>Welcome to Example Co</h1></header>\n",
    "    <section>\n",
    "      <h2>About</h2>\n",
    "      <p>Example Co builds reliable web solutions for small businesses.</p>\n",
    "    </section>\n",
    "    <section>\n",
    "      <h2>Services</h2>\n",
    "      <ul>\n",
    "        <li>Web development</li>\n",
    "        <li>Content strategy</li>\n",
    "        <li>Marketing automation</li>\n",
    "      </ul>\n",
    "    </section>\n",
    "    <footer>Contact: hello@example.com</footer>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\".strip()\n",
    "\n",
    "fallback_related_pages = [\n",
    "    {\n",
    "        \"url\": \"https://example.com/contact\",\n",
    "        \"html\": \"\"\"\n",
    "        <html><body><h1>Contact Us</h1><p>Email: hello@example.com</p><p>Phone: 555-123-4567</p></body></html>\n",
    "        \"\"\".strip(),\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"Fallback main HTML length: {len(fallback_main_html)}\")\n",
    "print(f\"Fallback related pages: {len(fallback_related_pages)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcb8564",
   "metadata": {},
   "source": [
    "## 3. Define Core Functions and Classes\n",
    "\n",
    "We reuse existing services (scraper, cleaner, summarizer) and wrap them with small helpers to make the notebook resilient (graceful fallbacks, optional LLM).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55830da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "from app.services.brochure_generator.scraper import (\n",
    "    filter_related_links,\n",
    "    scrape_main_page,\n",
    "    scrape_related_pages,\n",
    ")\n",
    "from app.services.brochure_generator.content_cleaner import combine_and_clean\n",
    "from app.services.brochure_generator.llm_summarizer import generate_brochure\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"lab\")\n",
    "\n",
    "\n",
    "def scrape_all(url: str) -> tuple[str, list[str], list[dict[str, str]]]:\n",
    "    \"\"\"Scrape main page + filtered related pages. Falls back to empty on errors.\"\"\"\n",
    "    try:\n",
    "        main_html, links = scrape_main_page(url)\n",
    "        kept_links = filter_related_links(url, links)\n",
    "        related = scrape_related_pages(kept_links)\n",
    "        return main_html, kept_links, related\n",
    "    except Exception as exc:  # noqa: BLE001\n",
    "        logger.warning(\"Scrape failed (%s); using fallback data.\", exc)\n",
    "        return fallback_main_html, [], fallback_related_pages\n",
    "\n",
    "\n",
    "def clean_content(main_html: str, related_pages: list[dict[str, str]]) -> str:\n",
    "    \"\"\"Run the cleaner to produce a single text blob.\"\"\"\n",
    "    return combine_and_clean(main_html, related_pages)\n",
    "\n",
    "\n",
    "def maybe_generate_brochure(cleaned_text: str, *, run_llm: bool) -> Optional[str]:\n",
    "    \"\"\"Call the LLM only if requested and API key exists.\"\"\"\n",
    "    has_key = bool(settings.google_api_key)\n",
    "    if not run_llm or not has_key:\n",
    "        logger.info(\"LLM step skipped (run_llm=%s, key=%s)\", run_llm, has_key)\n",
    "        return None\n",
    "    try:\n",
    "        return generate_brochure(cleaned_text)\n",
    "    except Exception as exc:  # noqa: BLE001\n",
    "        logger.warning(\"LLM generation failed: %s\", exc)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97da49d2",
   "metadata": {},
   "source": [
    "## 4. Implement Main Execution Flow\n",
    "\n",
    "This ties everything together: scrape → filter → scrape related → clean → optional LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f076d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import shorten\n",
    "\n",
    "# Run the pipeline (scrape → clean → optional LLM)\n",
    "main_html, kept_links, related_pages = scrape_all(target_url)\n",
    "print(f\"Main HTML length: {len(main_html)}\")\n",
    "print(f\"Related links kept: {len(kept_links)} -> {kept_links[:5]}\")\n",
    "print(f\"Related pages scraped: {len(related_pages)}\")\n",
    "\n",
    "cleaned = clean_content(main_html, related_pages)\n",
    "print(f\"Cleaned text length: {len(cleaned)}\")\n",
    "print(\"Preview:\\n\", shorten(cleaned.replace(\"\\n\", \" \"), width=400, placeholder=\" ...\"))\n",
    "\n",
    "brochure_md = maybe_generate_brochure(cleaned, run_llm=RUN_LLM)\n",
    "if brochure_md:\n",
    "    print(\"\\n---\\nBrochure preview (first 800 chars):\\n\")\n",
    "    print(brochure_md[:800])\n",
    "else:\n",
    "    print(\"\\nLLM step skipped or failed (see logs above).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de487a0d",
   "metadata": {},
   "source": [
    "## 5. Add Unit Tests\n",
    "\n",
    "Quick pytest-style checks to ensure the cleaner works on fallback HTML and that the brochure generator can be invoked conditionally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a14f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cleaner_handles_basic_html():\n",
    "    cleaned = clean_content(fallback_main_html, fallback_related_pages)\n",
    "    assert \"Example Co\" in cleaned\n",
    "    assert \"Contact\" in cleaned\n",
    "\n",
    "\n",
    "def test_llm_guard_flag():\n",
    "    brochure = maybe_generate_brochure(\"short text\", run_llm=False)\n",
    "    assert brochure is None\n",
    "\n",
    "\n",
    "# Run the quick tests in-notebook\n",
    "if __name__ == \"__main__\":\n",
    "    test_cleaner_handles_basic_html()\n",
    "    test_llm_guard_flag()\n",
    "    print(\"Tests passed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b355a9",
   "metadata": {},
   "source": [
    "## 6. Run and Validate Outputs\n",
    "\n",
    "Execute the main flow and inspect the previews. Switch `RUN_LLM` to `True` and set your API key in `.env` to exercise Gemini.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d76b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple validation snapshot\n",
    "print(f\"Cleaned text chars: {len(cleaned)}\")\n",
    "print(\"Cleaned excerpt:\\n\", cleaned[:600])\n",
    "\n",
    "if brochure_md:\n",
    "    print(\"\\nBrochure excerpt:\\n\", brochure_md[:600])\n",
    "else:\n",
    "    print(\"Brochure not generated in this run.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
